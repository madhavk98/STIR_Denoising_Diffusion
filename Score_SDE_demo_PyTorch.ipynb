{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yang-song/score_sde_pytorch/blob/main/Score_SDE_demo_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJappt3toqj"
   },
   "source": [
    "# Preparation\n",
    "\n",
    "1. `git clone https://github.com/yang-song/score_sde_pytorch.git`\n",
    "\n",
    "2. Install [required packages](https://github.com/yang-song/score_sde_pytorch/blob/main/requirements.txt)\n",
    "\n",
    "3. `cd` into folder `score_sde_pytorch`, launch a local jupyter server and connect to colab following [these instructions](https://research.google.com/colaboratory/local-runtimes.html)\n",
    "\n",
    "4. Download pre-trained [checkpoints](https://drive.google.com/drive/folders/1tFmF_uh57O6lx9ggtZT_5LdonVK2cV-e?usp=sharing) and save them in the `exp` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qa9OIcJmUKmZ",
    "outputId": "8fde468b-2c95-4003-f0bd-20ddad5248e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 12:58:40.521537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/nvvm/lib64:/usr/local/cuda/lib64:\n",
      "2023-07-25 12:58:40.521573: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madhav/anaconda3/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madhav/anaconda3/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "#@title Autoload all modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import importlib\n",
    "import os\n",
    "import functools\n",
    "import itertools\n",
    "import torch\n",
    "from losses import get_optimizer\n",
    "from models.ema import ExponentialMovingAverage\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_gan as tfgan\n",
    "import tqdm\n",
    "import io\n",
    "import likelihood\n",
    "import controllable_generation\n",
    "from utils import restore_checkpoint\n",
    "sns.set(font_scale=2)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import models\n",
    "from models import utils as mutils\n",
    "from models import ncsnv2\n",
    "from models import ncsnpp\n",
    "from models import ddpm as ddpm_model\n",
    "from models import layerspp\n",
    "from models import layers\n",
    "from models import normalization\n",
    "import sampling\n",
    "from likelihood import get_likelihood_fn\n",
    "from sde_lib import VESDE, VPSDE, subVPSDE\n",
    "from sampling import (ReverseDiffusionPredictor, \n",
    "                      LangevinCorrector, \n",
    "                      EulerMaruyamaPredictor, \n",
    "                      AncestralSamplingPredictor, \n",
    "                      NoneCorrector, \n",
    "                      NonePredictor,\n",
    "                      AnnealedLangevinDynamics)\n",
    "import datasets\n",
    "print(\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "-reedYgCU79v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  centered: false\n",
      "  dataset: LSUN\n",
      "  image_size: 256\n",
      "  num_channels: 1\n",
      "  random_flip: true\n",
      "  uniform_dequantization: false\n",
      "device: !!python/object/apply:torch.device\n",
      "- cuda\n",
      "- 0\n",
      "eval:\n",
      "  batch_size: 512\n",
      "  begin_ckpt: 50\n",
      "  bpd_dataset: test\n",
      "  enable_bpd: false\n",
      "  enable_loss: true\n",
      "  enable_sampling: true\n",
      "  end_ckpt: 96\n",
      "  num_samples: 50000\n",
      "model:\n",
      "  attention_type: ddpm\n",
      "  attn_resolutions: !!python/tuple\n",
      "  - 16\n",
      "  beta_max: 20.0\n",
      "  beta_min: 0.1\n",
      "  ch_mult: !!python/tuple\n",
      "  - 1\n",
      "  - 1\n",
      "  - 2\n",
      "  conditional: true\n",
      "  conv_size: 3\n",
      "  dropout: 0.0\n",
      "  ema_rate: 0.999\n",
      "  embedding_type: fourier\n",
      "  fir: true\n",
      "  fir_kernel:\n",
      "  - 1\n",
      "  - 3\n",
      "  - 3\n",
      "  - 1\n",
      "  fourier_scale: 16\n",
      "  init_scale: 0.0\n",
      "  name: ncsnpp\n",
      "  nf: 128\n",
      "  nonlinearity: swish\n",
      "  normalization: GroupNorm\n",
      "  num_res_blocks: 2\n",
      "  num_scales: 2000\n",
      "  progressive: output_skip\n",
      "  progressive_combine: sum\n",
      "  progressive_input: input_skip\n",
      "  resamp_with_conv: true\n",
      "  resblock_type: biggan\n",
      "  scale_by_sigma: true\n",
      "  sigma_max: 348\n",
      "  sigma_min: 0.01\n",
      "  skip_rescale: true\n",
      "optim:\n",
      "  beta1: 0.9\n",
      "  eps: 1.0e-08\n",
      "  grad_clip: 1.0\n",
      "  lr: 0.0002\n",
      "  optimizer: Adam\n",
      "  warmup: 5000\n",
      "  weight_decay: 0\n",
      "sampling:\n",
      "  corrector: langevin\n",
      "  method: pc\n",
      "  n_steps_each: 1\n",
      "  noise_removal: true\n",
      "  predictor: reverse_diffusion\n",
      "  probability_flow: false\n",
      "  snr: 0.075\n",
      "seed: 42\n",
      "training:\n",
      "  batch_size: 64\n",
      "  continuous: true\n",
      "  eval_freq: 100\n",
      "  likelihood_weighting: false\n",
      "  log_freq: 50\n",
      "  n_iters: 2400001\n",
      "  reduce_mean: false\n",
      "  sde: vesde\n",
      "  snapshot_freq: 50000\n",
      "  snapshot_freq_for_preemption: 5000\n",
      "  snapshot_sampling: true\n",
      " config data\n",
      "True GPU AVAILABLE\n",
      "cuda:0 config device\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m ema \u001b[38;5;241m=\u001b[39m ExponentialMovingAverage(score_model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     37\u001b[0m                                decay\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mema_rate)\n\u001b[1;32m     38\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     39\u001b[0m              model\u001b[38;5;241m=\u001b[39mscore_model, ema\u001b[38;5;241m=\u001b[39mema)\n\u001b[0;32m---> 41\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m ema\u001b[38;5;241m.\u001b[39mcopy_to(score_model\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m~/score_sde_pytorch/utils.py:15\u001b[0m, in \u001b[0;36mrestore_checkpoint\u001b[0;34m(ckpt_dir, state, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m   loaded_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(ckpt_dir, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 15\u001b[0m   \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m   state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mload_state_dict(loaded_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m   state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mload_state_dict(loaded_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:171\u001b[0m, in \u001b[0;36mOptimizer.load_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    169\u001b[0m saved_lens \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(g[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m saved_groups)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(p_len \u001b[38;5;241m!=\u001b[39m s_len \u001b[38;5;28;01mfor\u001b[39;00m p_len, s_len \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(param_lens, saved_lens)):\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded state dict contains a parameter group \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the size of optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms group\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Update the state\u001b[39;00m\n\u001b[1;32m    175\u001b[0m id_map \u001b[38;5;241m=\u001b[39m {old_id: p \u001b[38;5;28;01mfor\u001b[39;00m old_id, p \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    176\u001b[0m           \u001b[38;5;28mzip\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable((g[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m saved_groups)),\n\u001b[1;32m    177\u001b[0m               chain\u001b[38;5;241m.\u001b[39mfrom_iterable((g[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m groups)))}\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "# @title Load the score-based model\n",
    "sde = 'VESDE' #@param ['VESDE', 'VPSDE', 'subVPSDE'] {\"type\": \"string\"}\n",
    "if sde.lower() == 'vesde':\n",
    "  from configs.ve import stir_ncsnpp_continuous as configs\n",
    "  ckpt_filename = \"checkpoints/checkpoint_9.pth\"\n",
    "  config = configs.get_config()  \n",
    "  sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=int(50))\n",
    "  sampling_eps = 1e-5\n",
    "elif sde.lower() == 'vpsde':\n",
    "  from configs.vp import cifar10_ddpmpp_continuous as configs  \n",
    "  ckpt_filename = \"exp/vp/cifar10_ddpmpp_continuous/checkpoint_8.pth\"\n",
    "  config = configs.get_config()\n",
    "  sde = VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
    "  sampling_eps = 1e-3\n",
    "elif sde.lower() == 'subvpsde':\n",
    "  from configs.subvp import cifar10_ddpmpp_continuous as configs\n",
    "  ckpt_filename = \"exp/subvp/cifar10_ddpmpp_continuous/checkpoint_26.pth\"\n",
    "  config = configs.get_config()\n",
    "  sde = subVPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
    "  sampling_eps = 1e-3\n",
    "print(config, \"config data\")\n",
    "print(torch.cuda.is_available(), \"GPU AVAILABLE\")\n",
    "print(config.device, \"config device\")\n",
    "batch_size =   1#@param {\"type\":\"integer\"}\n",
    "config.training.batch_size = batch_size\n",
    "config.eval.batch_size = batch_size\n",
    "\n",
    "random_seed = 0 #@param {\"type\": \"integer\"}\n",
    "\n",
    "sigmas = mutils.get_sigmas(config)\n",
    "scaler = datasets.get_data_scaler(config)\n",
    "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
    "score_model = mutils.create_model(config)\n",
    "\n",
    "optimizer = get_optimizer(config, score_model.parameters())\n",
    "ema = ExponentialMovingAverage(score_model.parameters(),\n",
    "                               decay=config.model.ema_rate)\n",
    "state = dict(step=0, optimizer=optimizer,\n",
    "             model=score_model, ema=ema)\n",
    "\n",
    "state = restore_checkpoint(ckpt_filename, state, config.device)\n",
    "ema.copy_to(score_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "G8ei2Xsfg6JQ"
   },
   "outputs": [],
   "source": [
    "#@title Visualization code\n",
    "\n",
    "def image_grid(x):\n",
    "  size = config.data.image_size\n",
    "  channels = config.data.num_channels\n",
    "  img = x.reshape(-1, size, size, channels)\n",
    "  w = int(np.sqrt(img.shape[0]))\n",
    "  img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n",
    "  return img\n",
    "\n",
    "def show_samples(x):\n",
    "  x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "  img = image_grid(x)\n",
    "  plt.figure(figsize=(8,8))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hbBGjCMNUsp"
   },
   "source": [
    "# Predictor Corrector sampling\n",
    "\n",
    "\n",
    "Recommended settings:\n",
    "\n",
    " | dataset | SDE | predictor | corrector | snr | n_steps |\n",
    "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
    "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
    "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
    "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
    "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
    "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |\n",
    "\n",
    "Check `probability_flow` to run PC sampling based on discretizing the probability flow ODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "_X41BhiLqJvM",
    "outputId": "8a5b3b5f-93ad-4baf-d66f-0a648f935170"
   },
   "outputs": [],
   "source": [
    "# #@title PC sampling\n",
    "# img_size = config.data.image_size\n",
    "# channels = config.data.num_channels\n",
    "# shape = (batch_size, channels, img_size, img_size)\n",
    "# predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "# corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "# snr = 0.16 #@param {\"type\": \"number\"}\n",
    "# n_steps =  1#@param {\"type\": \"integer\"}\n",
    "# probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "# sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
    "#                                       inverse_scaler, snr, n_steps=n_steps,\n",
    "#                                       probability_flow=probability_flow,\n",
    "#                                       continuous=config.training.continuous,\n",
    "#                                       eps=sampling_eps, device=config.device)\n",
    "\n",
    "# x, n = sampling_fn(score_model)\n",
    "# show_samples(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AdiQdwN2aFA"
   },
   "source": [
    "# Probability flow ODE\n",
    "\n",
    "With black-box ODE solvers, we can produce samples, compute likelihoods, and obtain a uniquely identifiable encoding of any data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "iLQDfFvHSIGn",
    "outputId": "f1888e8b-4e70-446d-d248-9f1c1b6a7916"
   },
   "outputs": [],
   "source": [
    "#  #@title ODE sampling\n",
    "\n",
    "# shape = (batch_size, 3, 32, 32)\n",
    "# sampling_fn = sampling.get_ode_sampler(sde,                                        \n",
    "#                                        shape, \n",
    "#                                        inverse_scaler,                                       \n",
    "#                                        denoise=True, \n",
    "#                                        eps=sampling_eps,\n",
    "#                                        device=config.device)\n",
    "# x, nfe = sampling_fn(score_model)\n",
    "# show_samples(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "MsdcLnhu7s46"
   },
   "outputs": [],
   "source": [
    "# #@title Likelihood computation\n",
    "# train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=True, evaluation=True)\n",
    "# eval_iter = iter(eval_ds)\n",
    "# bpds = []\n",
    "# likelihood_fn = likelihood.get_likelihood_fn(sde,                                              \n",
    "#                                              inverse_scaler,                                             \n",
    "#                                              eps=1e-5)\n",
    "# for batch in eval_iter:\n",
    "#   img = batch['image']._numpy()\n",
    "#   img = torch.tensor(img).permute(0, 3, 1, 2).to(config.device)\n",
    "#   img = scaler(img)\n",
    "#   bpd, z, nfe = likelihood_fn(score_model, img)\n",
    "#   bpds.extend(bpd)\n",
    "#   print(f\"average bpd: {torch.tensor(bpds).mean().item()}, NFE: {nfe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "oe3rLGRm28nc",
    "outputId": "4d3b614b-df5b-4523-aa91-a223d6134397"
   },
   "outputs": [],
   "source": [
    "# #@title Representations\n",
    "# train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=False, evaluation=True)\n",
    "# eval_batch = next(iter(eval_ds))\n",
    "# eval_images = eval_batch['image']._numpy()\n",
    "# shape = (batch_size, 3, 32, 32)\n",
    "\n",
    "# likelihood_fn = likelihood.get_likelihood_fn(sde, inverse_scaler, eps=1e-5)\n",
    "# sampling_fn = sampling.get_ode_sampler(sde, shape, inverse_scaler,\n",
    "#                                        denoise=True, eps=sampling_eps, device=config.device)\n",
    "\n",
    "# plt.figure(figsize=(18, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(image_grid(eval_images))\n",
    "# plt.title('Original images')\n",
    "\n",
    "# eval_images = torch.from_numpy(eval_images).permute(0, 3, 1, 2).to(config.device)\n",
    "# _, latent_z, _ = likelihood_fn(score_model, scaler(eval_images))\n",
    "\n",
    "# x, nfe = sampling_fn(score_model, latent_z)\n",
    "\n",
    "# x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(image_grid(x))\n",
    "# plt.title('Reconstructed images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaGYVD7KcoW6"
   },
   "source": [
    "# Controllable generation\n",
    "\n",
    "Several demonstrations on how to solve inverse problems with our SDE framework.\n",
    "\n",
    "Recommended settings\n",
    "\n",
    "| dataset | SDE | predictor | corrector | snr | n_steps |\n",
    "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
    "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
    "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
    "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
    "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
    "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tbly_8RIjqJD",
    "outputId": "28ca290e-1079-4031-e37a-c69374398f76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# @title PC inpainting\n",
    "# train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
    "# eval_iter = iter(eval_ds)\n",
    "import time\n",
    "bpds = []\n",
    "\n",
    "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "snr = 0.16 #@param {\"type\": \"number\"}\n",
    "n_steps = 1 #@param {\"type\": \"integer\"}\n",
    "probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "\n",
    "pc_inpainter = controllable_generation.get_pc_inpainter(sde,\n",
    "                                                        predictor, corrector,\n",
    "                                                        inverse_scaler,\n",
    "                                                        snr=snr,\n",
    "                                                        n_steps=n_steps,\n",
    "                                                        probability_flow=probability_flow,\n",
    "                                                        continuous=config.training.continuous,\n",
    "                                                        denoise=True)\n",
    "# batch = next(eval_iter)\n",
    "# img = batch['image']._numpy()\n",
    "# img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "data_transform = transforms.Resize((config.data.image_size, config.data.image_size))\n",
    "img = torch.load('zed_channel0.pt').unsqueeze(0)\n",
    "img = data_transform(img)\n",
    "# img = torch.repeat_interleave(img, batch_size, axis=0)\n",
    "print(img.shape, \"IMG shape zed\")\n",
    "# show_samples(img)\n",
    "sample_grid = make_grid(img[0,...], nrow=int(np.sqrt(batch_size)))\n",
    "# plt.figure(figsize=(6,6))\n",
    "plt.clf()\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_grid.permute(1, 2, 0).cpu()[..., 0], vmin=0., vmax=1.)\n",
    "plt.show()\n",
    "plt.savefig('256_sde_original.png')\n",
    "\n",
    "\n",
    "\n",
    "mask = np.load('binary_mask.npy')\n",
    "mask = np.expand_dims(mask, axis=0)\n",
    "# mask = np.repeat(mask, 3, axis=0)\n",
    "mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mask = data_transform(mask.float())\n",
    "mask = mask.to(config.device)\n",
    "print(mask.shape, \"mask shape\")\n",
    "print(torch.count_nonzero(mask == 0), \"zeros\")\n",
    "\n",
    "# print the number of ones in mask\n",
    "print(torch.count_nonzero(mask == 1), \"ones\")\n",
    "\n",
    "print(mask.shape, \"mask shape\")\n",
    "print(sde.N, \"SDE.N\")\n",
    "img_mask = img*mask\n",
    "sample_grid = make_grid(img_mask[0,...], nrow=int(np.sqrt(batch_size)))\n",
    "# plt.figure(figsize=(6,6))\n",
    "plt.clf()\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_grid.permute(1, 2, 0).cpu()[..., 0], vmin=0., vmax=1.)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('256_sde_masked.png')\n",
    "\n",
    "start_time = time.time()\n",
    "x = pc_inpainter(score_model, scaler(img), mask)\n",
    "print(\"TIME TAKEN: \", time.time() - start_time)\n",
    "# show_samples(x)\n",
    "sample_grid = make_grid(x[0,...], nrow=int(np.sqrt(batch_size)))\n",
    "# plt.figure(figsize=(6,6))\n",
    "plt.clf()\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_grid.permute(1, 2, 0).cpu()[..., 0], vmin=0., vmax=1.)\n",
    "plt.show()\n",
    "plt.savefig('256_sde_unmasked.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img==img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DsP-ayb8cupk",
    "outputId": "51272ecd-4ba3-4931-8a6d-358c6218e25b"
   },
   "outputs": [],
   "source": [
    "from torchmetrics import PeakSignalNoiseRatio\n",
    "psnr = PeakSignalNoiseRatio()\n",
    "print(psnr(x.cpu(), img.cpu()), \"PSNR\")\n",
    "print(x.shape, img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiYRNB-Wk329"
   },
   "source": [
    "## Class-conditional generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTu-5e6S68Gb"
   },
   "source": [
    "Check out the [class-conditional generation section](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55#scrollTo=HiYRNB-Wk329&line=3&uniqifier=1) in our [JAX demo](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55?usp=sharing)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Score SDE demo PyTorch",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
